import tokenize_uk
import stanza


def into_sentences_table(text: str) -> set:
    pass


def divide_into_subsamples(clear_tokens: list) -> list:
    pass


def into_word_forms_table(sentences: tuple) -> set:
    pass


def into_lemmas_table(word_forms: tuple) -> set:
    pass


def into_pos_table(lemmas: tuple) -> set:
    pass
